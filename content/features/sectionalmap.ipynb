{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformat NetCDF4 File for Function Call ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: netCDF4 in /Users/VeerGadodia/.local/lib/python3.7/site-packages (1.5.1.2)\n",
      "Requirement already satisfied: numpy>=1.7 in /Applications/anaconda3/lib/python3.7/site-packages (from netCDF4) (1.16.2)\n",
      "Requirement already satisfied: cftime in /Applications/anaconda3/lib/python3.7/site-packages (from netCDF4) (1.0.3.4)\n",
      "Requirement already satisfied: xarray in /Applications/anaconda3/lib/python3.7/site-packages (0.12.1)\n",
      "Requirement already satisfied: numpy>=1.12 in /Applications/anaconda3/lib/python3.7/site-packages (from xarray) (1.16.2)\n",
      "Requirement already satisfied: pandas>=0.19.2 in /Applications/anaconda3/lib/python3.7/site-packages (from xarray) (0.24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /Applications/anaconda3/lib/python3.7/site-packages (from pandas>=0.19.2->xarray) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in /Applications/anaconda3/lib/python3.7/site-packages (from pandas>=0.19.2->xarray) (2018.9)\n",
      "Requirement already satisfied: six>=1.5 in /Applications/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.5.0->pandas>=0.19.2->xarray) (1.12.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "import opedia\n",
    "import sys\n",
    "!{sys.executable} -m pip install netCDF4\n",
    "!{sys.executable} -m pip install xarray\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import netCDF4\n",
    "import xarray as xr\n",
    "import datetime as dt\n",
    "from scipy.interpolate import griddata\n",
    "import db\n",
    "import subset\n",
    "import common as com\n",
    "import climatology as clim\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.layouts import column\n",
    "from bokeh.palettes import all_palettes\n",
    "from bokeh.models import HoverTool, LinearColorMapper, BasicTicker, ColorBar\n",
    "from bokeh.embed import components\n",
    "import jupyterInline as jup\n",
    "if jup.jupytered():\n",
    "    from tqdm import tqdm_notebook as tqdm\n",
    "else:\n",
    "    from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sectionMap(tables, variabels, dt1, dt2, lat1, lat2, lon1, lon2, depth1, depth2, fname, exportDataFlag):\n",
    "    data, lats, lons, subs, frameVars, units = [], [], [], [], [], []\n",
    "    xs, ys, zs = [], [], []\n",
    "    for i in tqdm(range(len(tables)), desc='overall'):\n",
    "        if not db.hasField(tables[i], 'depth'):\n",
    "            continue        \n",
    "        df = subset.section(tables[i], variabels[i], dt1, dt2, lat1, lat2, lon1, lon2, depth1, depth2)\n",
    "        if len(df) < 1:\n",
    "            com.printTQDM('%d: No matching entry found: Table: %s, Variable: %s ' % (i+1, tables[i], variabels[i]), err=True )\n",
    "            continue\n",
    "        com.printTQDM('%d: %s retrieved (%s).' % (i+1, variabels[i], tables[i]), err=False)\n",
    "\n",
    "        ############### export retrieved data ###############\n",
    "        if exportDataFlag:      # export data\n",
    "            dirPath = 'data/'\n",
    "            if not os.path.exists(dirPath):\n",
    "                os.makedirs(dirPath)                \n",
    "            exportData(df, path=dirPath + fname + '_' + tables[i] + '_' + variabels[i] + '.csv')\n",
    "        #####################################################\n",
    "\n",
    "        times = df[df.columns[0]].unique()\n",
    "        lats = df.lat.unique()\n",
    "        lons = df.lon.unique()\n",
    "        depths = df.depth.unique()\n",
    "        shape = (len(lats), len(lons), len(depths))\n",
    "        \n",
    "        print('------------------Times:')\n",
    "        print(times)\n",
    "        print('------------------Lats:')\n",
    "        print(lats)\n",
    "        print('------------------Lons:')\n",
    "        print(lons)\n",
    "        print('------------------Depths:')\n",
    "        print(depths)\n",
    "\n",
    "        hours =  [None]\n",
    "        if 'hour' in df.columns:\n",
    "            hours = df.hour.unique()\n",
    "\n",
    "        unit = com.getUnit(tables[i], variabels[i])\n",
    "        \n",
    "        print(hours)\n",
    "\n",
    "        for t in times:\n",
    "            for h in hours:\n",
    "                frame = df[df[df.columns[0]] == t]\n",
    "                sub = variabels[i] + unit + ', ' + df.columns[0] + ': ' + str(t) \n",
    "                if h != None:\n",
    "                    frame = frame[frame['hour'] == h]\n",
    "                    sub = sub + ', hour: ' + str(h) + 'hr'\n",
    "                try:    \n",
    "                    shot = frame[variabels[i]].values.reshape(shape)\n",
    "                except Exception as e:\n",
    "                    continue    \n",
    "                data.append(shot)\n",
    "                \n",
    "                xs.append(lons)\n",
    "                ys.append(lats)\n",
    "                zs.append(depths)\n",
    "\n",
    "                frameVars.append(variabels[i])\n",
    "                units.append(unit)\n",
    "                subs.append(sub)\n",
    "                \n",
    "    print(data)            \n",
    "    bokehSec(data=data, subject=subs, fname=fname, ys=ys, xs=xs, zs=zs, units=units, variabels=frameVars)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NetCDF Compatible Function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xarraySectionMap(tables, variabels, dt1, dt2, lat1, lat2, lon1, lon2, depth1, depth2, fname, exportDataFlag):\n",
    "    data, lats, lons, subs, frameVars, units = [], [], [], [], [], []\n",
    "    xs, ys, zs = [], [], []\n",
    "    for i in tqdm(range(len(tables)), desc='overall'):\n",
    "        \n",
    "        toDateTime = tables[i].indexes['TIME'].to_datetimeindex()\n",
    "        tables[i]['TIME'] = toDateTime\n",
    "        table = tables[i].sel(TIME = slice(dt1, dt2), LAT_C = slice(lat1, lat2), LON_C = slice(lon1, lon2), DEP_C = slice(depth1, depth2))\n",
    "        ############### export retrieved data ###############\n",
    "        if exportDataFlag:      # export data\n",
    "            dirPath = 'data/'\n",
    "            if not os.path.exists(dirPath):\n",
    "                os.makedirs(dirPath)                \n",
    "            exportData(df, path=dirPath + fname + '_' + tables[i] + '_' + variabels[i] + '.csv')\n",
    "        #####################################################\n",
    "\n",
    "        times = np.unique(table.variables['TIME'].values)\n",
    "        lats = np.unique(table.variables['LAT_C'].values)\n",
    "        lons = np.unique(table.variables['LON_C'].values)\n",
    "        depths = np.unique(table.variables['DEP_C'].values)\n",
    "        shape = (len(lats), len(lons), len(depths))\n",
    "        \n",
    "        hours = [None]\n",
    "\n",
    "        unit = '[PLACEHOLDER]'\n",
    "\n",
    "        for t in times:\n",
    "            for h in hours:\n",
    "                frame = table.sel(TIME = t, method = 'nearest')\n",
    "                sub = variabels[i] + unit + ', TIME: ' + str(t) \n",
    "                if h != None:\n",
    "                    frame = frame[frame['hour'] == h]\n",
    "                    sub = sub + ', hour: ' + str(h) + 'hr'\n",
    "                try:    \n",
    "                    shot = frame[variabels[i]].values.reshape(shape)\n",
    "                    shot[shot < 0] = float('NaN')\n",
    "                except Exception as e:\n",
    "                    continue    \n",
    "                data.append(shot)\n",
    "                \n",
    "                xs.append(lons)\n",
    "                ys.append(lats)\n",
    "                zs.append(depths)\n",
    "\n",
    "                frameVars.append(variabels[i])\n",
    "                units.append(unit)\n",
    "                subs.append(sub)\n",
    "    \n",
    "    print(data)\n",
    "    bokehSec(data=data, subject=subs, fname=fname, ys=ys, xs=xs, zs=zs, units=units, variabels=frameVars)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bokehSec(data, subject, fname, ys, xs, zs, units, variabels):\n",
    "    TOOLS=\"crosshair,pan,wheel_zoom,zoom_in,zoom_out,box_zoom,undo,redo,reset,tap,save,box_select,poly_select,lasso_select,\"\n",
    "    w = 1000\n",
    "    h = 500\n",
    "    p = []\n",
    "    data_org = list(data)\n",
    "    for ind in range(len(data_org)):\n",
    "        data = data_org[ind]\n",
    "        lon = xs[ind]\n",
    "        lat = ys[ind]\n",
    "        depth = zs[ind]      \n",
    "        \n",
    "        bounds = (None, None)\n",
    "        paletteName = com.getPalette(variabels[ind], 10)\n",
    "        low, high = bounds[0], bounds[1]\n",
    "        if low == None:\n",
    "            print(\"low: \")\n",
    "            print(np.min(data[ind]))\n",
    "            low, high = np.nanmin(data[ind].flatten()), np.nanmax(data[ind].flatten())\n",
    "        color_mapper = LinearColorMapper(palette=paletteName, low=low, high=high)\n",
    "        \n",
    "        print(\"low: \" + str(low))\n",
    "        print(\"high: \" + str(high))\n",
    "        \n",
    "        if len(lon) > len(lat):\n",
    "            p1 = figure(tools=TOOLS, toolbar_location=\"above\", title=subject[ind], plot_width=w, plot_height=h, x_range=(np.min(lon), np.max(lon)), y_range=(-np.max(depth), -np.min(depth)))\n",
    "            data = np.nanmean(data, axis=0)\n",
    "            data = np.transpose(data)\n",
    "            data = np.squeeze(data)\n",
    "            xLabel = 'Longitude'\n",
    "            data = regulate(lat, lon, depth, data)\n",
    "            p1.image(image=[data], color_mapper=color_mapper, x=np.min(lon), y=-np.max(depth), dw=np.max(lon)-np.min(lon), dh=np.max(depth)-np.min(depth))\n",
    "        else:\n",
    "            p1 = figure(tools=TOOLS, toolbar_location=\"above\", title=subject[ind], plot_width=w, plot_height=h, x_range=(np.min(lat), np.max(lat)), y_range=(-np.max(depth), -np.min(depth)))\n",
    "            data = np.nanmean(data, axis=1)\n",
    "            data = np.transpose(data)\n",
    "            data = np.squeeze(data)\n",
    "            xLabel = 'Latitude'      \n",
    "            data = regulate(lat, lon, depth, data)\n",
    "            p1.image(image=[data], color_mapper=color_mapper, x=np.min(lat), y=-np.max(depth), dw=np.max(lat)-np.min(lat), dh=np.max(depth)-np.min(depth))\n",
    "\n",
    "        p1.xaxis.axis_label = xLabel\n",
    "        p1.add_tools(HoverTool(\n",
    "            tooltips=[\n",
    "                (xLabel.lower(), '$x'),\n",
    "                ('depth', '$y'),\n",
    "                (variabels[ind]+units[ind], '@image'),\n",
    "            ],\n",
    "            mode='mouse'\n",
    "        ))\n",
    "\n",
    "        p1.yaxis.axis_label = 'depth [m]'\n",
    "        color_bar = ColorBar(color_mapper=color_mapper, ticker=BasicTicker(),\n",
    "                        label_standoff=12, border_line_color=None, location=(0,0))\n",
    "        p1.add_layout(color_bar, 'right')\n",
    "        p.append(p1)\n",
    "    dirPath = 'embed/'\n",
    "    if not os.path.exists(dirPath):\n",
    "        os.makedirs(dirPath)        \n",
    "   # if not inline:      ## if jupyter is not the caller\n",
    "   #     output_file(dirPath + fname + \".html\", title=\"Section Map\")\n",
    "    show(column(p))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regulate(lat, lon, depth, data):\n",
    "    depth = -1* depth \n",
    "    deltaZ = np.min( np.abs( depth - np.roll(depth, -1) ) )\n",
    "    newDepth =  np.arange(np.min(depth), np.max(depth), deltaZ)        \n",
    "\n",
    "    if len(lon) > len(lat):\n",
    "        lon1, depth1 = np.meshgrid(lon, depth)\n",
    "        lon2, depth2 = np.meshgrid(lon, newDepth)\n",
    "        lon1 = lon1.ravel()\n",
    "        lon1 = list(lon1[lon1 != np.isnan])\n",
    "        depth1 = depth1.ravel()\n",
    "        depth1 = list(depth1[depth1 != np.isnan])\n",
    "        data = data.ravel()\n",
    "        data = list(data[data != np.isnan])\n",
    "        data = griddata((lon1, depth1), data, (lon2, depth2), method='linear')\n",
    "    else:   \n",
    "        lat1, depth1 = np.meshgrid(lat, depth)\n",
    "        lat2, depth2 = np.meshgrid(lat, newDepth)\n",
    "        lat1 = lat1.ravel()\n",
    "        lat1 = list(lat1[lat1 != np.isnan])\n",
    "        depth1 = depth1.ravel()\n",
    "        depth1 = list(depth1[depth1 != np.isnan])\n",
    "        data = data.ravel()\n",
    "        data = list(data[data != np.isnan])\n",
    "        data = griddata((lat1, depth1), data, (lat2, depth2), method='linear')\n",
    "\n",
    "    depth = -1* depth \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Space ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS TESTS THE ORIGINAL SECTIONAL FUNCTION\n",
    "\n",
    "tables = ['tblDarwin_Nutrient_Climatology']    # see catalog.csv  for the complete list of tables and variable names\n",
    "variabels = ['CDOM_darwin_clim']                            # see catalog.csv  for the complete list of tables and variable names\n",
    "\n",
    "dt1 = '2016-04-30'   # PISCES is a weekly model, and here we are using monthly climatology of Darwin model\n",
    "dt2 = '2016-04-30'\n",
    "lat1, lat2 = 23, 55\n",
    "lon1, lon2 = -159, -157\n",
    "depth1, depth2 = 0, 3597\n",
    "fname = 'sectional'\n",
    "exportDataFlag = False       # True if you you want to download data\n",
    "\n",
    "sectionMap(tables, variabels, dt1, dt2, lat1, lat2, lon1, lon2, depth1, depth2, fname, exportDataFlag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c0c385e7da346bdaaed117c6e55ec21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='overall', max=1, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[array([[[217.72581 , 216.81123 , 214.0529  , ..., 230.42786 ,\n",
      "         229.17262 , 231.33789 ],\n",
      "        [233.9318  , 234.01979 , 231.77782 , ..., 266.105   ,\n",
      "         266.24622 , 272.6455  ],\n",
      "        [271.14008 , 267.5709  , 270.03146 , ..., 291.15668 ,\n",
      "         289.13187 , 286.4821  ],\n",
      "        [293.4539  , 290.29108 , 288.36252 , ..., 317.2291  ,\n",
      "         316.32886 , 314.52707 ]],\n",
      "\n",
      "       [[317.17874 , 315.7166  , 314.08313 , ..., 325.32346 ,\n",
      "         325.19644 , 324.50272 ],\n",
      "        [324.8363  , 324.9312  , 323.8824  , ..., 218.6293  ,\n",
      "         216.3647  , 214.4391  ],\n",
      "        [218.26263 , 220.42119 , 218.32784 , ..., 247.69958 ,\n",
      "         236.04405 , 233.75935 ],\n",
      "        [242.77306 , 244.85489 , 251.91418 , ..., 269.25162 ,\n",
      "         270.12946 , 274.0666  ]],\n",
      "\n",
      "       [[276.8333  , 274.2667  , 274.4905  , ..., 289.88556 ,\n",
      "         289.83417 , 289.1105  ],\n",
      "        [293.06216 , 291.07034 , 290.4885  , ..., 316.25833 ,\n",
      "         313.7674  , 312.94287 ],\n",
      "        [317.34076 , 317.73276 , 318.027   , ..., 323.91815 ,\n",
      "         323.8229  , 323.13007 ],\n",
      "        [325.03622 , 324.5677  , 324.23425 , ..., 223.38698 ,\n",
      "         221.38574 , 215.03766 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[118.56813 , 122.07851 , 124.37722 , ..., 138.89113 ,\n",
      "         138.28128 , 138.15404 ],\n",
      "        [138.55788 , 138.34163 , 137.74638 , ..., 133.62332 ,\n",
      "         132.74957 , 133.28917 ],\n",
      "        [132.97987 , 132.95703 , 132.69957 , ..., 129.67747 ,\n",
      "         128.99763 , 130.27586 ],\n",
      "        [131.3726  , 130.79448 , 131.56548 , ..., 124.89965 ,\n",
      "         126.59851 , 125.47857 ]],\n",
      "\n",
      "       [[125.57555 , 125.44564 , 125.426025, ..., 127.749275,\n",
      "         127.31362 , 127.262085],\n",
      "        [127.70962 , 127.40387 , 126.59454 , ..., 125.88385 ,\n",
      "         129.53844 , 133.18211 ],\n",
      "        [125.24015 , 129.04002 , 129.05605 , ..., 145.91988 ,\n",
      "         144.16055 , 143.67812 ],\n",
      "        [145.19058 , 144.38684 , 143.67772 , ..., 141.33304 ,\n",
      "         141.07362 , 141.54594 ]],\n",
      "\n",
      "       [[140.71703 , 141.06773 , 141.67303 , ..., 139.8576  ,\n",
      "         139.12973 , 138.6735  ],\n",
      "        [139.78937 , 139.35306 , 138.66321 , ..., 135.03003 ,\n",
      "         134.89113 , 134.96988 ],\n",
      "        [134.81976 , 135.67053 , 135.26762 , ..., 135.24072 ,\n",
      "         135.11833 , 134.84845 ],\n",
      "        [136.04054 , 136.10843 , 135.20757 , ...,        nan,\n",
      "                nan,        nan]]], dtype=float32)]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'common' has no attribute 'getPalette'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7edc638e03fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mexportDataFlag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m       \u001b[0;31m# True if you you want to download data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mxarraySectionMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlat1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlat2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlon1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlon2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexportDataFlag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-1bd4eab91519>\u001b[0m in \u001b[0;36mxarraySectionMap\u001b[0;34m(tables, variabels, dt1, dt2, lat1, lat2, lon1, lon2, depth1, depth2, fname, exportDataFlag)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mbokehSec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframeVars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-081a40424678>\u001b[0m in \u001b[0;36mbokehSec\u001b[0;34m(data, subject, fname, ys, xs, zs, units, variabels)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mbounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mpaletteName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetPalette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlow\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'common' has no attribute 'getPalette'"
     ]
    }
   ],
   "source": [
    "#TESTS NETCDF-COMPATIBLE FUNCTION\n",
    "xFile = xr.open_dataset('http://3.88.71.225:80/thredds/dodsC/las/id-a1d60eba44/data_usr_local_tomcat_content_cbiomes_20190510_20_darwin_v0.2_cs510_darwin_v0.2_cs510_nutrients.nc.jnl')\n",
    "\n",
    "tables = [xFile]    # see catalog.csv  for the complete list of tables and variable names\n",
    "variabels = ['O2']                            # see catalog.csv  for the complete list of tables and variable name\n",
    "dt1 = '2016-04-21'   # PISCES is a weekly model, and here we are using monthly climatology of Darwin model\n",
    "dt2 = '2016-04-23'\n",
    "lat1, lat2 = 23, 55\n",
    "lon1, lon2 = -159, -157\n",
    "depth1, depth2 = 0, 3597\n",
    "fname = 'sectional'\n",
    "exportDataFlag = False       # True if you you want to download data\n",
    "\n",
    "xarraySectionMap(tables, variabels, dt1, dt2, lat1, lat2, lon1, lon2, depth1, depth2, fname, exportDataFlag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
